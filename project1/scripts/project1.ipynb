{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "name": "project1.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "GeJIOjfTNACa"
      },
      "source": [
        "# Useful starting lines\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3eJRayn0NBqy",
        "outputId": "c4266da8-7a3f-4f5a-b74e-65ae9c0a3eae"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "to8e0cuvNACh"
      },
      "source": [
        "## Load the training data into feature matrix, class labels, and event ids:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "biOnBCTYNACj"
      },
      "source": [
        "from proj1_helpers import *\n",
        "DATA_TRAIN_PATH = 'drive/MyDrive/train.csv' # train data path here \n",
        "y, tX, ids = load_csv_data(DATA_TRAIN_PATH)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M7HktZX2NACk"
      },
      "source": [
        "## Do your thing crazy machine learning thing here :) ..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s3DKg7Z_NACk"
      },
      "source": [
        "def compute_loss(y, tx, w):\n",
        "    N = y.shape[0]\n",
        "    e=y-tx@w\n",
        "    loss = (1/(2*N))*np.dot(e,e)\n",
        "    return loss"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PAXF5SwHNACl"
      },
      "source": [
        "def compute_gradient(y, tx, w):\n",
        "    N = y.shape[0]\n",
        "    e = y-tx@w\n",
        "    gradient = -(1/N)*(tx.T)@(e)\n",
        "    return gradient"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4szpkJm5NACm"
      },
      "source": [
        "def least_squares_GD(y, tx, initial_w, max_iters, gamma):\n",
        "    ws = [initial_w]\n",
        "    losses = []\n",
        "    w = initial_w\n",
        "    for n_iter in range(max_iters):\n",
        "        loss = compute_loss(y,tx,w)\n",
        "        gradient = compute_gradient(y,tx,w)\n",
        "        w = w-gamma*gradient\n",
        "        ws.append(w)\n",
        "        losses.append(loss)\n",
        "        print(\"Gradient Descent({bi}/{ti}): loss={l}, w0={w0}, w1={w1}\".format(\n",
        "              bi=n_iter, ti=max_iters - 1, l=loss, w0=w[0], w1=w[1]))\n",
        "    return losses, ws"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M-bu-OYkNACn"
      },
      "source": [
        "def compute_stoch_gradient(y, tx, w):\n",
        "    N = y.shape[0]\n",
        "    random_number = random.randint(0,N)\n",
        "    #random_number =1\n",
        "    xn = tx[random_number,:]\n",
        "    random_gradient = -np.dot(xn, y[random_number]-np.dot(xn,w))\n",
        "    return random_gradient"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ysZYYw0NACo"
      },
      "source": [
        "def least_squares_SGD(y, tx, initial_w, max_iters, gamma):\n",
        "    ws = [initial_w]\n",
        "    losses = []\n",
        "    w = initial_w\n",
        "    for n_iter in range(max_iters):\n",
        "        loss = compute_loss(y,tx,w)\n",
        "        stoch_gradient = compute_stoch_gradient(y,tx,w)\n",
        "        w = w-gamma*stoch_gradient\n",
        "        ws.append(w)\n",
        "        losses.append(loss)\n",
        "        print(\"Gradient Descent({bi}/{ti}): loss={l}, w0={w0}, w1={w1}\".format(\n",
        "              bi=n_iter, ti=max_iters - 1, l=loss, w0=w[0], w1=w[1]))\n",
        "    return losses, ws"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I23t7prqNACp"
      },
      "source": [
        "from proj1_helpers import *\n",
        "\n",
        "def least_squares(y, tx):\n",
        "    \"\"\"calculate the least squares solution.\"\"\"\n",
        "    forcing_term = np.transpose(tx) @ y\n",
        "    coefficient_matrix = np.transpose(tx) @ tx\n",
        "    w = np.linalg.solve(coefficient_matrix, forcing_term)\n",
        "    return w\n",
        "\n",
        "def test_your_least_squares(y, tx):\n",
        "    \"\"\"compare the solution of the normal equations with the weights returned by gradient descent algorithm.\"\"\"\n",
        "    w_least_squares = least_squares(y, tx)\n",
        "    initial_w = np.zeros(tx.shape[1])\n",
        "    max_iters = 50\n",
        "    gamma = 0.7\n",
        "    losses_gradient_descent, w_gradient_descent = gradient_descent(y, tx, initial_w, max_iters, gamma)\n",
        "    w = w_gradient_descent[-1]\n",
        "    err = np.linalg.norm(w_least_squares-w)\n",
        "    return err"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_oByYtzNACq"
      },
      "source": [
        "def ridge_regression(y, tx, lambda_):\n",
        "    \"\"\"implement ridge regression.\"\"\"\n",
        "    N = tx.shape\n",
        "    lambda_prime = 2 * N[0] * lambda_\n",
        "    coefficient_matrix = np.transpose(tx) @ tx + lambda_prime * np.eye(N[1])\n",
        "    forcing_term = np.transpose(tx) @ y\n",
        "    w = np.linalg.solve(coefficient_matrix, forcing_term)\n",
        "    return w\n",
        "\n",
        "def debug_ridge(y, tx):\n",
        "    \"\"\"debugging the ridge regression by setting lambda=0.\"\"\"\n",
        "    w_least_squares = least_squares(y, tx)\n",
        "    w_0 = ridge_regression(y, tx, 0)\n",
        "    err = np.linalg.norm(w_least_squares-w_0)\n",
        "    return err"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rqmZyqQsNACr"
      },
      "source": [
        "## Generate predictions and save ouput in csv format for submission:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "PeI82r5FNACs"
      },
      "source": [
        "DATA_TEST_PATH = 'drive/MyDrive/test.csv' # TODO: download train data and supply path here \n",
        "_, tX_test, ids_test = load_csv_data(DATA_TEST_PATH)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "h4YVTKWCNACs",
        "outputId": "fc091f8a-79db-4890-952e-92372e85d535"
      },
      "source": [
        "OUTPUT_PATH = '' # TODO: fill in desired name of output file for submission\n",
        "y_pred = predict_labels(weights, tX_test)\n",
        "create_csv_submission(ids_test, y_pred, OUTPUT_PATH)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'weights' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipykernel_118/2223051364.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mOUTPUT_PATH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m''\u001b[0m \u001b[0;31m# TODO: fill in desired name of output file for submission\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mcreate_csv_submission\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mids_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOUTPUT_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'weights' is not defined"
          ]
        }
      ]
    }
  ]
}